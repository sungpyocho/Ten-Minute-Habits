# Particle Filter



### 파티클 필터가 겪는 문제들

#### 1. 퇴화 현상 (Degeneracy Problem)

&#x20; 알고리즘 1을 사용할 경우, 몇 번의 반복 이후에는 한 파티클의 가중치가 거의 1에 가까워지고 다른 모든 파티클의 가중치는 거의 0이 된다. 이 현상을 퇴화 현상이라고 한다. 퇴화 현상으로 인해 발생하는 문제점은 두 가지이다. 하나는 거의 모든 계산 노력이 추정에 거의 기여하지 않는 파티클을 계산하는 데에 사용된다는 것이다. 다른 하나는 효과적인 파티클이 오직 하나밖에 없다는 것이다.&#x20;

&#x20; 특히 후자는 필터의 성능과 표현력을 크게 제한한다. 먼저 성능 하락은 파티클 필터가 발산하기 때문에 일어난다. 발산은 상태 추정 오류가 시간이 지남에 따라 용납할 수 없을 정도로 크게 증가했을 때 발생한다. 발산하는 단계에 들어서면, 필터는 진짜 상태를 따라가거나 추정 오류를 용납할 수 있을 정도로 줄이는 데 실패한다. 다음으로 표현력 제한은 하나의 파티클이 임의의 형태의 확률 밀도 함수가 아닌, 상태 공간에서의 한 점만을 표현할 수 있기 때문에 발생한다.

&#x20; 이 문제를 해결하기 위한 방법은 리샘플링이다. 업데이트 단계 직후에 수행되는 리샘플링에서, 새로운 파티클은 가중치를 지닌 파티클 집합에서 무작위로 선택된다. 파티클을 선택할 확률은 그 파티클의 가중치에 비례한다. 전체 파티클의 수는 변하지 않는다. 높은 가중치를 지닌 파티클은 중복된 가능성이 높고, 낮은 가중치를 지닌 파티클은 제거될 가능성이 높다. 리샘플링 후에는 일반적으로 가중치가 $$1/N_S$$로 설정된다.

#### 2. 샘플 빈곤화 (Sample Impoverishment)

&#x20; 리샘플링을 통해 퇴화 현상을 해결하면 동일한 가중치를 가진 여러 인스턴스가 생성된다. 중요도 밀도(importance density)로 가장 일반적인 $$p(x^i_k | x^i_{k-1})$$ 을 고른다고 가정하면, 예측 단계는 결정론적 부분과 확률론적 부분을 포함한다. 결과적으로, 동일한 상태의 파티클은 예측 단계 동안 다양화 될 것이다. 만약 프로세스 모델의 노이즈 분산이 매우 낮다면, 샘플은 거의 다양화되지 않는다. 이 경우, 몇 번의 반복 끝에 모든 파티클이 상태 공간에서 단일 지점으로 수렴하게 된다. 그러면 모든 $$N_s$$ 파티클이 동일한 상태를 나타내게 된다. 필터가 사실상 하나의 파티클로만 이루어지게 되는 것이다. 이를 바로 샘플 빈곤화라고 한다. 퇴화 현상과 마찬가지로, 필터는 성능과 표현력을 잃고, 발산하게 된다.

&#x20; 일반적으로 프로세스 모델의 노이즈를 충분한 양으로 설정하면 샘플 빈곤화를 막을 수 있다. 뒤에서 해결책에 대해 더욱 자세히 설명할 것이다.

#### 3. 발산 (Divergence)

&#x20; 실제 문제에 파티클 필터를 사용할 때, 발산 위험을 항상 고려해야 한다. 왜 필터가 발산하는 걸까? 이유는 필터의 부적절한 설정이나 잘못된 모델링 가정, 일관성 없는 측정 데이터 또는 하드웨어 실패에 이르기까지 다양할 수 있다. 관측 노이즈 가정이 정확하지 않거나, 프로세스 모델이 정확하지 않게 가정된 경우도 포함된다. 따라서 이러한 발산이 발생하지 않도록, 파티클 필터를 모니터링 해 줘야 한다.

#### 4. 중요도 밀도 선택 (Selecting the Importance Density)

&#x20; 중요도 밀도는 파티클 필터 알고리즘의 핵심이다, 적절한 함수를 선택하는 것은 필터 설계 시 가장 중요한 단계 중 하나이다. 예를 들어, 추정해야 할 사후 분포는 평균이 0인 가우시안 분포인데, 중요도 밀도는 균등 분포를 설정했다고 가정하자. 이 때 중요도 밀도의 선택은 유효(valid)하지만 그다지 정보적(informative)이지는 않다. 즉, 최소한의 요건은 충족하지만 최적의 해결책은 아니라는 것이다.

&#x20; 알기 쉽게 설명해보겠다. 먼저 균등 분포의 선택이 유효한 이유를 살펴보자. 균등 분포는 모든 가능한 상태에 대해 동일한 확률을 부여하여, 파티클이 상태 공간 전체에 분포될 수 있게 한다. 덕분에 광범위한 상태 공간을 탐색하며 가능한 상태를 선택할 수 있다. 따라서 유효하다.

&#x20; 그러나 이 선택은 그다지 정보적이지는 않다. 균등 분포는 문제의 특성이나 사전 지식을 반영하지 않는다. 추정해야 할 사후 분포가 평균이 0인 가우시안 분포라는 것을 떠올려 보자. 이 분포는 특정 위치에 대한 확률이 더 높다. 그러나 균등 분포는 모든 가능성을 동일하게 취급한다. 이로 인해 많은 파티클이 사후 분포의 중요하지 않은 영역에 할당될 수 있고, 이는 상태 추정의 정확도와 효율성을 떨어뜨린다. 결과적으로 부적절한 중요도 밀도를 통해 가우시안 분포의 형태를 잘 포착하기 위해서는, 상대적으로 많은 수의 파티클이 필요하다.

#### 5. 실시간 실행 (Real Time Execution)

&#x20; 파티클 필터는 추정하는 분포를 표현하기에 충분한 수의 파티클이 있을 때만 작동한다. 파티클의 수는 필터의 계산 비용에 직접적인 영향을 미친다.

### 파티클 필터가 겪는 문제들의 해결 방법

#### 1. 퇴화 현상 (Degeneracy Problem)의 해결

리샘플링을 언제, 어떻게 해야할지 도움이 되는 간단한 방법을 소개한다.

#### 1-1. '언제' 리샘플링을 할까?

&#x20; 먼저 리샘플링 시기를 어떻게 정해야 할까. 가장 간단한 방법은 '매 타임스텝 마다 하는 것'이다. 이는 퇴화 현상을 방지하는 가장 인기있는 방법 중 하나이다. 하지만 리샘플링은 연산 비용이 높기 때문에 부담이 된다. 또한 매번 리샘플링을 하면 파티클 집합의 다양성을 줄이기 때문에, 샘플 빈곤화의 위험을 높일 수도 있다. 따라서 매번 리샘플링을 실행하기 보다는, 조금 적은 빈도로 실행하더라도 퇴화 현상을 막을 수 있는 방법을 찾는 것이 좋다.

<figure><img src="../.gitbook/assets/Screenshot 2024-02-16 at 19.14.55.png" alt=""><figcaption><p>매번 리샘플링을 하는 알고리즘</p></figcaption></figure>

&#x20; 파티클의 퇴화를 평가할 수 있는 좋은 지표가 있다면 리샘플링의 빈도를 줄이면서 효과적으로 퇴화 현상을 방지할 수 있을 것이다. 가장 많이 쓰이는 방법은 '효과적인 샘플 사이즈' $$\hat{N}_{\text{eff}}$$을 사용해 리샘플링할 시기를 정하는 것이다. 효과적인 샘플 사이즈란, 확률 분포에 유의미하게 기여하는 파티클의 개수를 뜻한다. 다음과 같은 식으로 구할 수 있다.

$$
\hat{N}_{\text{eff}} = \frac{1}{\sum_{i=1}^{N_s} (w_k^i)^2}
$$

여기서 $$w_i$$는 $$i$$번째 파티클의 가중치이다. 효과적인 파티클 수가 전체 파티클 수 $$N_s$$에 비해 상당히 낮다면, 이는 소수의 파티클만이 전체 추정치에 대부분 기여하고 있다는 신호이다. 따라서 . 따라서, $$\hat{N}_{\text{eff}}$$이 $$N_s$$에 비해 작은 값을 가질 때, 리샘플링을 수행한다.&#x20;

만약 $$\hat{N}_{\text{eff}}$$가 특정 임계값, 예를 들어 $$N_s/2$$ 보다 작다면, 파티클 가중치의 분산이 충분하지 않다고 판단하고 리샘플링을 통해 파티클을 다시 균일하게 분포시키게 된다. 이 과정은 전체 가중치에 기여하는 파티클의 다양성을 높여, 필터의 성능을 유지하고 발산을 방지하는데 도움이 된다. 밑의 이미지는 $$\hat{N}_{\text{eff}}$$에 기반해 리샘플링의 시기를 정하는 알고리즘의 의사 코드이다.

<figure><img src="../.gitbook/assets/Screenshot 2024-02-16 at 19.32.20.png" alt=""><figcaption><p><span class="math">\hat{N}_{\text{eff}}</span>에 기반해 리샘플링의 시기를 정하는 알고리즘</p></figcaption></figure>

대부분의 파티클 필터는 위에서 제시한 두 가지 리샘플링 시점 기준 중 하나를 사용한다. 특히 상태의 차원이 낮다면 더욱 그렇다. 그러나 다른 방법으로도 효과적인 샘플 수를 측정할 수 있다. 한 가지 방법은 효과적인 샘플 사이즈를$$1 / \max_i(w_k^i)$$으로 계산하고, 이 값이 특정 임계값 밑으로 떨어지면 리샘플링을 하는 것이다.&#x20;

위 방법이 효과가 없다면, 덜 일반적인 재샘플링 기준을 선택할 수 있다. 예를 들면, 사전에 정의된 값보다 낮은 가중치를 가진 파티클만을 리샘플링 대상으로 삼는 것이다. 더 나아가 해결하고자 하는 문제의 기존 지식이 있다면, 특정 영역의 상태 공간에서 파티클을 재생성할 수 있다.&#x20;

또 다른 접근 방법은 결정론적 재샘플링(deterministic resampling)이다. 리샘플링을 할 때, 파티클의 가중치뿐만 아니라 상태도 고려되어, 낮은 가중치를 가진 파티클을 무차별적으로 버리는 것을 피하는 방법이다.&#x20;

#### 1-2. '어떻게' 리샘플링을 할까?

리샘플링은 $$N_s$$개의 가중치가 더해진 파티클을 새로운 $$N_s$$개의 (주로 균등한) 가중치가 더해진 파티클로 바꾸는 확률적인 단계이다. 물론 파티클의 수를 실시간으로 변경하는 방법론도 있으나, 여기에서는 일단 파티클의 수가 일정하다고 가정하자.

리샘플링 알고리즘은 다양하다. 그러나 대부분의 파티클 필터는 다항 리샘플링(multinomial resampling), 잔여 리샘플링(resuidual resampling), 체계적 리샘플링(systematic resampling), 계층화 리샘플링(stratified resampling) 중 하나의 알고리즘을 사용한다.

일반적으로, 최고의 리샘플링 알고리즘은 존재하지 않는다. 체계적 리샘플링이 다항 리샘플링보다 성능이 나쁘다는 논문도 있는 반면, 체계적 리샘플링이 그 결과의 질과 계산 복잡도 측면에서 가장 좋은 알고리즘이라고 주장하는 논문도 있다.&#x20;

어느 알고리즘을 사용해야 할지 결정해야 할 때는 '예측 가능성'의 차이를 인식하면 좋다. 먼저 동일한 파티클에 대해 한 가지 재샘플링 알고리즘을 여러 번 적용했을 때, 결과의 일관성을 기대할 수 있어야 한다. 그렇지 못하면 매 실행마다 매우 다른 결과가 나올 수 있다. 또한 일부 재샘플링 방법은 선택 과정에서 편향을 초래할 수 있기 때문에 주의해야 한다. 예를 들어, 특정 파티클이 과다하게 선택된다면, 전체 파티클 집합의 추정 확률 분포를 왜곡할 수 있다. 따라서 알고리즘의 예측 가능성의 차이를 인식하고, 이를 요구사항에 맞추어 적절하게 선택하는 것이 중요하다.

#### 2. 샘플 빈곤화 (Sample Impoverishment)의 해결

샘플 빈곤화를 다루는 여러가지 방법을 설명한다.

#### 2-1. 조잡화 (Roughening)

샘플 빈곤화를 피하기 위해서는 어떻게 해야 할까? 쉽게 떠오르는 방법은 프로세스 모델의 노이즈를 인위적으로 증가시키는 것이다. 학계에서는 다음의 두 가지 방법론을 제시한다.

* 재샘플링 후 인공적인 노이즈를 추가
* 전파 단계에서 사용된 프로세스 모델에 흐트러짐(jitter)를 추가

이 조잡화를 언제 적용힐지, 얼마나 많은 노이즈를 추가해야 하는지, 어떤 차원에 적용해야 하는지는 일반적으로 딱 집어 말하기는 어렵다. 그러나 다음 사항을 염두해 두자.

* 조잡화는 샘플 빈곤화에 효과적인 조치가 될 수 있다.
* 파티클의 수가 상대적으로 적을 경우, 조잡화가 더 유용하다.
* 조잡화 방법의 복잡성은 필요에 따라 튜닝될 수 있으며, 파티클 필터 튜닝 과정의 일부이다.

#### 2-2. 보조 파티클 필터 (Auxiliary Particle Filters)

표준 파티클 필터에서, 첫 번째 단계인 예측은 임의로 샘플을 추출한다. 두 번째 단계인 보정은 관측치와 첫 번째 단계에서 예측된 파티클의 상태를 사용해 가중치를 업데이트한다. 보조 파티클 필터의 역할은 예측 단계에서, 관측치를 보정 단계에 통합한 후에 높은 가능도를 얻을 것 같은 파티클을 선호하는 것이다. 이를 위해서는, 최신 관측치를 예측 단계에서 활용해야 한다. 사전 분포에서 무작정 샘플을 뽑는 것이 아니다. 보조 파티클 필터의 알고리즘을 요약하면 다음과 같다.

1.

